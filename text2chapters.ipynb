{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "import whisper_timestamped as whisper\n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "download(\"stopwords\")\n",
    "YT_LINK = \"/content/vid test.weba\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hardcoded text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"content/oleg.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    txt = f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizerFast\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from transformers.pipelines import pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "russian_stopwords = set(stopwords.words(\"russian\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_checkpoint = 'bert-base-multilingual-cased'\n",
    "hf_model = pipeline(\"feature-extraction\", model=\"bert-base-multilingual-cased\")\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_checkpoint)\n",
    "model = BertModel.from_pretrained(model_checkpoint)\n",
    "model = model.eval()\n",
    "\n",
    "\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    embeddings = outputs.pooler_output\n",
    "    normalized_embeddings = F.normalize(embeddings, p=2)\n",
    "\n",
    "    return normalized_embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pymystem3 import mystem\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    m = mystem.Mystem()\n",
    "    lemmas = m.lemmatize(text)\n",
    "    lemmas = [l for l in lemmas if l.isalpha()]\n",
    "    return \" \".join(lemmas)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kw_model = KeyBERT(model=hf_model)\n",
    "window_size = 200\n",
    "stride = 50\n",
    "\n",
    "txt = preprocess_text(txt)\n",
    "txt = txt.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "txt = txt.replace(\".\", \"\").replace(\",\", \"\")\n",
    "txt = txt.lower()\n",
    "tokens = txt.split()\n",
    "tokens = [t for t in tokens if t not in russian_stopwords]\n",
    "\n",
    "indexed_keywords = {}\n",
    "frags = []\n",
    "df = pd.DataFrame(columns=[\"index\", \"keywords\", \"fragments\"])\n",
    "for i in range(0, len(tokens) - window_size, stride):\n",
    "    frag = tokens[i: i + window_size]\n",
    "    frag = \" \".join([f.lower() for f in frag])\n",
    "    frags.append(frag)\n",
    "    keywords = kw_model.extract_keywords(frag, keyphrase_ngram_range=(1, 1), top_n=10, use_mmr=True)\n",
    "    indexed_keywords[i] = keywords"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "values_dict = {\"index\": [], \"keywords\": []}\n",
    "for i, keywords in indexed_keywords.items():\n",
    "    words = \" \".join([k[0] for k in keywords])\n",
    "\n",
    "    values_dict[\"index\"].append(i)\n",
    "    values_dict[\"keywords\"].append(words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(values_dict)\n",
    "df[\"fragments\"] = frags\n",
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Retrieve embeddings from the DataFrame\n",
    "TARGET_COL = 'fragments'\n",
    "\n",
    "df['embedding'] = df[TARGET_COL].apply(lambda x: get_embeddings(x).numpy()[0])\n",
    "embeddings = df['embedding'].tolist()\n",
    "\n",
    "dimension = len(embeddings[0])\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings).astype('float32'))\n",
    "\n",
    "# Calculate the distance between every row and the next one\n",
    "distances = []\n",
    "for i in range(len(embeddings) - 1):\n",
    "    distance = index.search(np.array([embeddings[i]]).astype('float32'), 2)[0][0][1]\n",
    "    distances.append(distance)\n",
    "\n",
    "# Append the distances to the DataFrame\n",
    "df['distance_to_next'] = distances + [None]  # The last row\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"distance_to_next\"].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "words_dataset = Dataset.from_pandas(df)\n",
    "words_dataset = words_dataset.map(\n",
    "    lambda x: {'text_embeddings': get_embeddings(x[\"keywords\"])[0]}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "words_dataset.to_pandas().head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores, samples = words_dataset.get_nearest_examples('text_embeddings', test_frag_1, k=words_dataset.shape[0])\n",
    "demo_df = pd.DataFrame({\"index\": samples['index']})\n",
    "demo_df[\"score_to_1\"] = scores\n",
    "demo_df[\"keywords\"] = demo_df[\"index\"].apply(lambda x: [w[0] for w in indexed_keywords[x]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "demo_df[\"score/dist\"] = demo_df[\"score_to_1\"] / demo_df[\"index\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "    index  score_to_1                                           keywords  \\\n0      50    0.000000  [обучаться, практиковать, собеседник, приглаша...   \n1    1600    0.041696  [заинтересовывать, встречаться, заинтересованн...   \n2    1650    0.041696  [заинтересовывать, встречаться, заинтересованн...   \n3     100    0.044245  [практиковать, взаимодействовать, обучаться, р...   \n4    1550    0.046017  [встречаться, заинтересовывать, увлекать, заин...   \n5    1500    0.051990  [поработать, заинтересованность, увлекать, инт...   \n6    1400    0.053479  [интердисциплинарный, поработать, сформировыва...   \n7     200    0.054806  [монокорпоративный, ведущая, преподаватель, пр...   \n8     900    0.054976  [являться, заинтересовывать, пользователь, пос...   \n9    1050    0.055510  [заинтересовывать, проговаривать, встречаться,...   \n10    750    0.058236  [заинтересовывать, отправлять, присоединяться,...   \n11   1250    0.064071  [ориентироваться, приглашать, заинтересованный...   \n12   1900    0.065881  [сгруппироваться, встречаться, скажем, сколачи...   \n13    600    0.068904  [заинтересовывать, псевмагистратура, раскидыва...   \n14   1350    0.070010  [выбирать, рекомендательный, поработать, показ...   \n15   1200    0.070366  [ориентироваться, приглашать, встречаться, заи...   \n16    300    0.071517  [монокорпоративный, сгруппироваться, определен...   \n17   1000    0.072681  [заинтересовывать, проговаривать, являться, го...   \n18    700    0.076354  [подключаться, отправлять, раскидывать, являть...   \n19   1700    0.078588  [встречаться, верифицировать, замотивировать, ...   \n20   1850    0.078970  [сгруппироваться, верифицировать, развиваться,...   \n21    250    0.081818  [монокорпоративный, ведущая, преподаватель, ко...   \n22   1100    0.082225  [приглашать, встречаться, писать, рассказывать...   \n23    150    0.085492  [монокорпоративный, ведущая, приглашать, практ...   \n24    650    0.085720  [раскидывать, отправлять, подключаться, заинте...   \n25   1300    0.086223  [ориентироваться, заинтересованный, рекомендат...   \n26    500    0.089518  [заинтересованный, скажем, услышать, посмотрет...   \n27   1800    0.090594  [сгруппироваться, верифицировать, сколачивать,...   \n28      0    0.090795  [торжественный, произносить, приглашать, являт...   \n29    350    0.092117  [сгруппироваться, скажем, посмотреть, рассказы...   \n30    400    0.092310  [сгруппироваться, заинтересованный, скажем, оп...   \n31    950    0.095153  [заинтересовывать, проговаривать, взаимодейств...   \n32    800    0.098891  [отправлять, являться, сказать, называть, расс...   \n33   1750    0.101029  [верифицировать, комфортно, сказать, стоить, и...   \n34   1450    0.102917  [интердисциплинарный, поработать, выбирать, об...   \n35    850    0.105979  [пользователь, являться, сказать, искать, прог...   \n36    550    0.116830  [подключаться, услышать, заинтересованный, обр...   \n37   1150    0.129997  [приглашать, ориентироваться, встречаться, заи...   \n38    450    0.136375  [сгруппироваться, заинтересованный, услышать, ...   \n\n    score/dist  \n0     0.000000  \n1     0.000026  \n2     0.000025  \n3     0.000442  \n4     0.000030  \n5     0.000035  \n6     0.000038  \n7     0.000274  \n8     0.000061  \n9     0.000053  \n10    0.000078  \n11    0.000051  \n12    0.000035  \n13    0.000115  \n14    0.000052  \n15    0.000059  \n16    0.000238  \n17    0.000073  \n18    0.000109  \n19    0.000046  \n20    0.000043  \n21    0.000327  \n22    0.000075  \n23    0.000570  \n24    0.000132  \n25    0.000066  \n26    0.000179  \n27    0.000050  \n28         inf  \n29    0.000263  \n30    0.000231  \n31    0.000100  \n32    0.000124  \n33    0.000058  \n34    0.000071  \n35    0.000125  \n36    0.000212  \n37    0.000113  \n38    0.000303  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>score_to_1</th>\n      <th>keywords</th>\n      <th>score/dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>0.000000</td>\n      <td>[обучаться, практиковать, собеседник, приглаша...</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1600</td>\n      <td>0.041696</td>\n      <td>[заинтересовывать, встречаться, заинтересованн...</td>\n      <td>0.000026</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1650</td>\n      <td>0.041696</td>\n      <td>[заинтересовывать, встречаться, заинтересованн...</td>\n      <td>0.000025</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>0.044245</td>\n      <td>[практиковать, взаимодействовать, обучаться, р...</td>\n      <td>0.000442</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1550</td>\n      <td>0.046017</td>\n      <td>[встречаться, заинтересовывать, увлекать, заин...</td>\n      <td>0.000030</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1500</td>\n      <td>0.051990</td>\n      <td>[поработать, заинтересованность, увлекать, инт...</td>\n      <td>0.000035</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1400</td>\n      <td>0.053479</td>\n      <td>[интердисциплинарный, поработать, сформировыва...</td>\n      <td>0.000038</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>200</td>\n      <td>0.054806</td>\n      <td>[монокорпоративный, ведущая, преподаватель, пр...</td>\n      <td>0.000274</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>900</td>\n      <td>0.054976</td>\n      <td>[являться, заинтересовывать, пользователь, пос...</td>\n      <td>0.000061</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1050</td>\n      <td>0.055510</td>\n      <td>[заинтересовывать, проговаривать, встречаться,...</td>\n      <td>0.000053</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>750</td>\n      <td>0.058236</td>\n      <td>[заинтересовывать, отправлять, присоединяться,...</td>\n      <td>0.000078</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1250</td>\n      <td>0.064071</td>\n      <td>[ориентироваться, приглашать, заинтересованный...</td>\n      <td>0.000051</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1900</td>\n      <td>0.065881</td>\n      <td>[сгруппироваться, встречаться, скажем, сколачи...</td>\n      <td>0.000035</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>600</td>\n      <td>0.068904</td>\n      <td>[заинтересовывать, псевмагистратура, раскидыва...</td>\n      <td>0.000115</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1350</td>\n      <td>0.070010</td>\n      <td>[выбирать, рекомендательный, поработать, показ...</td>\n      <td>0.000052</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1200</td>\n      <td>0.070366</td>\n      <td>[ориентироваться, приглашать, встречаться, заи...</td>\n      <td>0.000059</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>300</td>\n      <td>0.071517</td>\n      <td>[монокорпоративный, сгруппироваться, определен...</td>\n      <td>0.000238</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1000</td>\n      <td>0.072681</td>\n      <td>[заинтересовывать, проговаривать, являться, го...</td>\n      <td>0.000073</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>700</td>\n      <td>0.076354</td>\n      <td>[подключаться, отправлять, раскидывать, являть...</td>\n      <td>0.000109</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1700</td>\n      <td>0.078588</td>\n      <td>[встречаться, верифицировать, замотивировать, ...</td>\n      <td>0.000046</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1850</td>\n      <td>0.078970</td>\n      <td>[сгруппироваться, верифицировать, развиваться,...</td>\n      <td>0.000043</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>250</td>\n      <td>0.081818</td>\n      <td>[монокорпоративный, ведущая, преподаватель, ко...</td>\n      <td>0.000327</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1100</td>\n      <td>0.082225</td>\n      <td>[приглашать, встречаться, писать, рассказывать...</td>\n      <td>0.000075</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>150</td>\n      <td>0.085492</td>\n      <td>[монокорпоративный, ведущая, приглашать, практ...</td>\n      <td>0.000570</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>650</td>\n      <td>0.085720</td>\n      <td>[раскидывать, отправлять, подключаться, заинте...</td>\n      <td>0.000132</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1300</td>\n      <td>0.086223</td>\n      <td>[ориентироваться, заинтересованный, рекомендат...</td>\n      <td>0.000066</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>500</td>\n      <td>0.089518</td>\n      <td>[заинтересованный, скажем, услышать, посмотрет...</td>\n      <td>0.000179</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1800</td>\n      <td>0.090594</td>\n      <td>[сгруппироваться, верифицировать, сколачивать,...</td>\n      <td>0.000050</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0</td>\n      <td>0.090795</td>\n      <td>[торжественный, произносить, приглашать, являт...</td>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>350</td>\n      <td>0.092117</td>\n      <td>[сгруппироваться, скажем, посмотреть, рассказы...</td>\n      <td>0.000263</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>400</td>\n      <td>0.092310</td>\n      <td>[сгруппироваться, заинтересованный, скажем, оп...</td>\n      <td>0.000231</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>950</td>\n      <td>0.095153</td>\n      <td>[заинтересовывать, проговаривать, взаимодейств...</td>\n      <td>0.000100</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>800</td>\n      <td>0.098891</td>\n      <td>[отправлять, являться, сказать, называть, расс...</td>\n      <td>0.000124</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>1750</td>\n      <td>0.101029</td>\n      <td>[верифицировать, комфортно, сказать, стоить, и...</td>\n      <td>0.000058</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>1450</td>\n      <td>0.102917</td>\n      <td>[интердисциплинарный, поработать, выбирать, об...</td>\n      <td>0.000071</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>850</td>\n      <td>0.105979</td>\n      <td>[пользователь, являться, сказать, искать, прог...</td>\n      <td>0.000125</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>550</td>\n      <td>0.116830</td>\n      <td>[подключаться, услышать, заинтересованный, обр...</td>\n      <td>0.000212</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>1150</td>\n      <td>0.129997</td>\n      <td>[приглашать, ориентироваться, встречаться, заи...</td>\n      <td>0.000113</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>450</td>\n      <td>0.136375</td>\n      <td>[сгруппироваться, заинтересованный, услышать, ...</td>\n      <td>0.000303</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence transformers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"content/oleg.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    txt = f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "sentences = txt.split(\".\")\n",
    "embeddings = model.encode(sentences)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_sentence_embeddings(sentence):\n",
    "    embeddings = model.encode(sentence)\n",
    "    return embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "values_dict = {\"index\":[], \"sentence\": [], \"embedding\": []}\n",
    "for i, sentence in enumerate(sentences):\n",
    "    values_dict[\"index\"].append(i)\n",
    "    values_dict[\"sentence\"].append(sentence.strip())\n",
    "    values_dict[\"embedding\"].append(get_sentence_embeddings(sentence))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(values_dict)\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentence_dataset = Dataset.from_pandas(df)\n",
    "sentence_dataset = sentence_dataset.add_faiss_index(column='embedding')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_frag_1 = sentence_dataset.to_pandas().head()['embedding'][1]\n",
    "sentence_dataset.to_pandas().head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores, samples = sentence_dataset.get_nearest_examples('embedding', test_frag_1, k=len(sentence_dataset))\n",
    "demo_df = pd.DataFrame({\"index\": samples['index'], \"fragment\": values_dict[\"sentence\"]})\n",
    "demo_df[\"score_to_1\"] = scores / scores.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "demo_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentence transformers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"content/test_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    txt = f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences = txt.split(\".\")\n",
    "sentences = [s.strip() for s in sentences if len(s) > 0]\n",
    "embeddings = model.encode(sentences)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_clusters = 4\n",
    "clustering_model = HDBSCAN(min_cluster_size=num_clusters, max_cluster_size=4)\n",
    "clustering_model.fit(embeddings)\n",
    "cluster_assignment = clustering_model.labels_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clustered_sentences = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(sentences[sentence_id])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "values_dict = {\"index\":[], \"sentence\": []}\n",
    "for i, sentence in enumerate(sentences):\n",
    "    values_dict[\"index\"].append(i)\n",
    "    values_dict[\"sentence\"].append(sentence.strip())\n",
    "\n",
    "df = pd.DataFrame(values_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    df[f\"cluster_{i}\"] = df[\"sentence\"].apply(lambda x: 1 if x in cluster else 0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
