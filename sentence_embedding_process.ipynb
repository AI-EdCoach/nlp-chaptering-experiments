{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from punctuators.models import SBDModelONNX"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:22:06.682462500Z",
     "start_time": "2024-03-26T08:22:00.672861800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(\"content/habr.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    txt = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:22:06.683492500Z",
     "start_time": "2024-03-26T08:22:06.672929500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-25T20:14:40.449835800Z",
     "start_time": "2024-03-25T20:14:27.026406600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: P-tune — если кратко, это автоматизированный подбор промпта (более детально об этом рассказал коллега в этой статье). Он работает эффективнее, чем человек, которого посадили подбирать удачный промпт. В целом это хороший подход, но в нашем случае он почти никогда не давал требуемых результатов с необходимым качеством. Сам подход не может именно научить модель: задача должна быть достаточно простой для модели или в каком-то виде присутствовать в обучении.\n",
      "\n",
      "Для сложных задач интереснее LoRA и fine-tune. На практике разница между ними в максимальном качестве, которого можно достичь: у разморозки слоёв в fine-tune предел качества выше. Но давайте рассмотрим каждый подход подробнее.\n",
      "\n",
      "У LoRA есть параметр — ранг. Чем больше ранг, тем более сложному навыку можно обучить модель. Но и тут есть свои нюансы. Мы проводили эксперимент с рангом LoRA и ростом качества в зависимости от него. Шаг ранга — степень двойки (4, 8, 16, 32, 64, 128, 256, 512). Спешу расстроить: экспоненциального роста качества модели, увы, не происходит.\n",
      "\n",
      "Мы выяснили, что лучше выбирать значение ранга 8 или 32. Ранг 8 — золотая середина, но с моделью, у которой изначально было низкое качество или неудачная архитектура, вы, скорее всего, быстро упрётесь в потолок. При ранге 32 модель начинает работать лучше и улавливать более мелкие детали. С дальнейшим увеличением ранга можно увидеть рост метрик, но по субъективным оценкам качество падает: модель начинает цепляться за ошибки в обучающих данных и чаще галлюцинировать.\n",
      "\n",
      "Обучение LoRA требует от 1000 до 50 000 примеров для обучения. На большем количестве обучающих примеров на наших данных мы не получали роста качества, хотя до этого была очевидная зависимость качества от количества данных.\n",
      "\n",
      "В случае fine-tune можно обучать модель целиком — full fine-tune. Для больших моделей такой вариант достаточно требователен к ресурсам, поэтому в качестве альтернативы можно обучать только часть слоёв. Обычно это называют «разморозкой»: модель по умолчанию «заморожена» и большинство весов зафиксированы. Если «разморозить» только необходимые слои, обучение будет быстрее, но проблемнее — спрогнозировать, какие слои размораживать, достаточно сложно. Full fine-tune позволяет получить максимальное качество на текущей архитектуре модели, но этот метод более требователен к количеству и качеству данных, чем LoRA и p-tune.\n",
      "\n",
      "Теперь мы знаем все плюсы и минусы всех подходов — что же выбрать? При малом количестве данных использование fine-tune приведёт к тому, что модель будет более подвержена prompt injection — исходя из наших наблюдений, с LoRA такое случается реже. В то же время при fine-tune потенциал качества выше — модель начинает улавливать больше интересных деталей. Кстати, это одновременно и плюс, и минус: при недостаточно качественном датасете модель обязательно научится чему-то плохому даже из всего лишь из пары примеров. В случае с LoRA с рангом 8 или 32 есть шанс, что такого не произойдёт. Однако, если есть идеальный датасет, то full fine-tune даст наибольшее качество.\n",
      "\n",
      "Для нас LoRa оказался эффективным препродакшн-инструментом для проведения множества экспериментов при подготовке датасета и проверке гипотез. Это метод позволяет быстро и дёшево исследовать различные подходы и идеи, не тратя много времени и ресурсов. Однако мы понимаем, что LoRa — неидеальное решение. Поэтому после того, как мы упираемся в потолок качества, переход на fine-tune даёт нам рост в качестве за счёт того, что у нас есть хорошо подготовленный качественный датасет.\n",
      "\n",
      "В целом сочетание LoRa и fine-tune позволяет нам эффективно использовать преимущества обоих методов для достижения лучших результатов. Такой подход мы применили для суммаризации страниц, и аналогичный подход применялся для пересказа видео.\n",
      "Outputs:\n",
      "\tP ⁇ tune  ⁇  если кратко, это автоматизированный подбор промпта  ⁇ более детально об этом рассказал коллега в этой статье ⁇ .\n",
      "\tОн работает эффективнее, чем человек, которого посадили подбирать удачный промпт.\n",
      "\tВ целом это хороший подход, но в нашем случае он почти никогда не давал требуемых результатов с необходимым качеством.\n",
      "\tСам подход не может именно научить модель ⁇  задача должна быть достаточно простой для модели или в каком ⁇ то виде присутствовать в обучении.\n",
      "\t ⁇ Для сложных задач интереснее LoRA и fine ⁇ tune.\n",
      "\tНа практике разница между ними в максимальном качестве, которого можно достичь ⁇  у разморозки слоёв в fine ⁇ tune предел качества выше.\n",
      "\tНо давайте рассмотрим каждый подход подробнее.\n",
      "\t ⁇ У LoRA есть параметр  ⁇  ранг.\n",
      "\tЧем больше ранг, тем более сложному навыку можно обучить модель.\n",
      "\tНо и тут есть свои нюансы.\n",
      "\tМы проводили экспер\n",
      "\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = SBDModelONNX.from_pretrained(\"sbd_multi_lang\")\n",
    "\n",
    "input_texts: List[str] = [\n",
    "    txt\n",
    "]\n",
    "\n",
    "results: List[List[str]] = m.infer(input_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sentence preprocess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sentences = re.split(r'\\.\\s|\\.\\n', txt)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    sentences[i] = sentence.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:22:06.685747800Z",
     "start_time": "2024-03-26T08:22:06.673440700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['P-tune — если кратко, это автоматизированный подбор промпта (более детально об этом рассказал коллега в этой статье)',\n 'Он работает эффективнее, чем человек, которого посадили подбирать удачный промпт',\n 'В целом это хороший подход, но в нашем случае он почти никогда не давал требуемых результатов с необходимым качеством',\n 'Сам подход не может именно научить модель: задача должна быть достаточно простой для модели или в каком-то виде присутствовать в обучении',\n 'Для сложных задач интереснее LoRA и fine-tune',\n 'На практике разница между ними в максимальном качестве, которого можно достичь: у разморозки слоёв в fine-tune предел качества выше',\n 'Но давайте рассмотрим каждый подход подробнее',\n 'У LoRA есть параметр — ранг',\n 'Чем больше ранг, тем более сложному навыку можно обучить модель',\n 'Но и тут есть свои нюансы',\n 'Мы проводили эксперимент с рангом LoRA и ростом качества в зависимости от него',\n 'Шаг ранга — степень двойки (4, 8, 16, 32, 64, 128, 256, 512)',\n 'Спешу расстроить: экспоненциального роста качества модели, увы, не происходит',\n 'Мы выяснили, что лучше выбирать значение ранга 8 или 32',\n 'Ранг 8 — золотая середина, но с моделью, у которой изначально было низкое качество или неудачная архитектура, вы, скорее всего, быстро упрётесь в потолок',\n 'При ранге 32 модель начинает работать лучше и улавливать более мелкие детали',\n 'С дальнейшим увеличением ранга можно увидеть рост метрик, но по субъективным оценкам качество падает: модель начинает цепляться за ошибки в обучающих данных и чаще галлюцинировать',\n 'Обучение LoRA требует от 1000 до 50 000 примеров для обучения',\n 'На большем количестве обучающих примеров на наших данных мы не получали роста качества, хотя до этого была очевидная зависимость качества от количества данных',\n 'В случае fine-tune можно обучать модель целиком — full fine-tune',\n 'Для больших моделей такой вариант достаточно требователен к ресурсам, поэтому в качестве альтернативы можно обучать только часть слоёв',\n 'Обычно это называют «разморозкой»: модель по умолчанию «заморожена» и большинство весов зафиксированы',\n 'Если «разморозить» только необходимые слои, обучение будет быстрее, но проблемнее — спрогнозировать, какие слои размораживать, достаточно сложно',\n 'Full fine-tune позволяет получить максимальное качество на текущей архитектуре модели, но этот метод более требователен к количеству и качеству данных, чем LoRA и p-tune',\n 'Теперь мы знаем все плюсы и минусы всех подходов — что же выбрать? При малом количестве данных использование fine-tune приведёт к тому, что модель будет более подвержена prompt injection — исходя из наших наблюдений, с LoRA такое случается реже',\n 'В то же время при fine-tune потенциал качества выше — модель начинает улавливать больше интересных деталей',\n 'Кстати, это одновременно и плюс, и минус: при недостаточно качественном датасете модель обязательно научится чему-то плохому даже из всего лишь из пары примеров',\n 'В случае с LoRA с рангом 8 или 32 есть шанс, что такого не произойдёт',\n 'Однако, если есть идеальный датасет, то full fine-tune даст наибольшее качество',\n 'Для нас LoRa оказался эффективным препродакшн-инструментом для проведения множества экспериментов при подготовке датасета и проверке гипотез',\n 'Это метод позволяет быстро и дёшево исследовать различные подходы и идеи, не тратя много времени и ресурсов',\n 'Однако мы понимаем, что LoRa — неидеальное решение',\n 'Поэтому после того, как мы упираемся в потолок качества, переход на fine-tune даёт нам рост в качестве за счёт того, что у нас есть хорошо подготовленный качественный датасет',\n 'В целом сочетание LoRa и fine-tune позволяет нам эффективно использовать преимущества обоих методов для достижения лучших результатов',\n 'Такой подход мы применили для суммаризации страниц, и аналогичный подход применялся для пересказа видео.']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:22:06.705291700Z",
     "start_time": "2024-03-26T08:22:06.685747800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizerFast\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from transformers.pipelines import pipeline\n",
    "\n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "download(\"stopwords\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:22:16.575842300Z",
     "start_time": "2024-03-26T08:22:06.705291700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "russian_stopwords = set(stopwords.words(\"russian\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:22:16.653025800Z",
     "start_time": "2024-03-26T08:22:16.577851300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_checkpoint = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "hf_model = pipeline(\"feature-extraction\", model=\"bert-base-multilingual-cased\")\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "embeddings = model.encode(sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:22:27.468495500Z",
     "start_time": "2024-03-26T08:22:16.612724200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "values_dict = {\"index\":[], \"sentence\": [], \"embedding\": []}\n",
    "for i, sentence in enumerate(sentences):\n",
    "    values_dict[\"index\"].append(i)\n",
    "    values_dict[\"sentence\"].append(sentences[i])\n",
    "    values_dict[\"embedding\"].append(embeddings[i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:22:27.485716200Z",
     "start_time": "2024-03-26T08:22:27.472529400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "   index                                           sentence  \\\n0      0  P-tune — если кратко, это автоматизированный п...   \n1      1  Он работает эффективнее, чем человек, которого...   \n2      2  В целом это хороший подход, но в нашем случае ...   \n3      3  Сам подход не может именно научить модель: зад...   \n4      4      Для сложных задач интереснее LoRA и fine-tune   \n\n                                           embedding  \n0  [-0.43873578, 0.0045500644, -0.058726426, -0.1...  \n1  [0.015044462, -0.043138217, -0.13492848, -0.08...  \n2  [-0.043706495, -0.15788434, -0.10562504, -0.30...  \n3  [-0.15333599, 0.059547313, -0.103571616, -0.04...  \n4  [-0.065739356, -0.106273375, -0.18514916, 0.14...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>sentence</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>P-tune — если кратко, это автоматизированный п...</td>\n      <td>[-0.43873578, 0.0045500644, -0.058726426, -0.1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Он работает эффективнее, чем человек, которого...</td>\n      <td>[0.015044462, -0.043138217, -0.13492848, -0.08...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>В целом это хороший подход, но в нашем случае ...</td>\n      <td>[-0.043706495, -0.15788434, -0.10562504, -0.30...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Сам подход не может именно научить модель: зад...</td>\n      <td>[-0.15333599, 0.059547313, -0.103571616, -0.04...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Для сложных задач интереснее LoRA и fine-tune</td>\n      <td>[-0.065739356, -0.106273375, -0.18514916, 0.14...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(values_dict)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:37:01.106136900Z",
     "start_time": "2024-03-26T08:37:00.821653800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dimension = len(embeddings[0])\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings).astype('float32'))\n",
    "\n",
    "distances = []\n",
    "for i in range(len(embeddings) - 1):\n",
    "    distance = index.search(np.array([embeddings[i]]).astype('float32'), 2)[0][0][1]\n",
    "    distances.append(distance)\n",
    "\n",
    "df['faiss_search'] = distances + [None]\n",
    "\n",
    "cos_dist = []\n",
    "for i in range(len(embeddings) - 1):\n",
    "    sim = cosine_similarity(embeddings[i].reshape(1, -1), embeddings[1+1].reshape(1, -1))[0][0]\n",
    "    cos_dist.append(sim)\n",
    "\n",
    "df['cos_sim'] = cos_dist + [None]\n",
    "df['super_score'] = df['faiss_search'] * df['cos_sim']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:39:17.159463200Z",
     "start_time": "2024-03-26T08:39:17.103316700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             sentence  super_score\n0   P-tune — если кратко, это автоматизированный п...     2.359216\n1   Он работает эффективнее, чем человек, которого...     3.913883\n2   В целом это хороший подход, но в нашем случае ...     8.857592\n3   Сам подход не может именно научить модель: зад...     3.668906\n4       Для сложных задач интереснее LoRA и fine-tune     2.052966\n5   На практике разница между ними в максимальном ...     3.880389\n6       Но давайте рассмотрим каждый подход подробнее     3.420843\n7                         У LoRA есть параметр — ранг     1.890748\n8   Чем больше ранг, тем более сложному навыку мож...     2.572504\n9                           Но и тут есть свои нюансы     2.193518\n10  Мы проводили эксперимент с рангом LoRA и росто...     2.387529\n11  Шаг ранга — степень двойки (4, 8, 16, 32, 64, ...     1.011330\n12  Спешу расстроить: экспоненциального роста каче...     3.975339\n13  Мы выяснили, что лучше выбирать значение ранга...     2.645053\n14  Ранг 8 — золотая середина, но с моделью, у кот...     3.283998\n15  При ранге 32 модель начинает работать лучше и ...     2.988543\n16  С дальнейшим увеличением ранга можно увидеть р...     3.169895\n17  Обучение LoRA требует от 1000 до 50 000 пример...     2.055877\n18  На большем количестве обучающих примеров на на...     4.647187\n19  В случае fine-tune можно обучать модель целико...     2.682445\n20  Для больших моделей такой вариант достаточно т...     2.824097\n21  Обычно это называют «разморозкой»: модель по у...     2.189540\n22  Если «разморозить» только необходимые слои, об...     2.796245\n23  Full fine-tune позволяет получить максимальное...     3.249875\n24  Теперь мы знаем все плюсы и минусы всех подход...     3.602189\n25  В то же время при fine-tune потенциал качества...     3.243859\n26  Кстати, это одновременно и плюс, и минус: при ...     3.599707\n27  В случае с LoRA с рангом 8 или 32 есть шанс, ч...     2.633625\n28  Однако, если есть идеальный датасет, то full f...     2.963593\n29  Для нас LoRa оказался эффективным препродакшн-...     2.051240\n30  Это метод позволяет быстро и дёшево исследоват...     4.493104\n31  Однако мы понимаем, что LoRa — неидеальное реш...     4.051621\n32  Поэтому после того, как мы упираемся в потолок...     3.467401\n33  В целом сочетание LoRa и fine-tune позволяет н...     2.801313\n34  Такой подход мы применили для суммаризации стр...          NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>super_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P-tune — если кратко, это автоматизированный п...</td>\n      <td>2.359216</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Он работает эффективнее, чем человек, которого...</td>\n      <td>3.913883</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>В целом это хороший подход, но в нашем случае ...</td>\n      <td>8.857592</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Сам подход не может именно научить модель: зад...</td>\n      <td>3.668906</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Для сложных задач интереснее LoRA и fine-tune</td>\n      <td>2.052966</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>На практике разница между ними в максимальном ...</td>\n      <td>3.880389</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Но давайте рассмотрим каждый подход подробнее</td>\n      <td>3.420843</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>У LoRA есть параметр — ранг</td>\n      <td>1.890748</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Чем больше ранг, тем более сложному навыку мож...</td>\n      <td>2.572504</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Но и тут есть свои нюансы</td>\n      <td>2.193518</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Мы проводили эксперимент с рангом LoRA и росто...</td>\n      <td>2.387529</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Шаг ранга — степень двойки (4, 8, 16, 32, 64, ...</td>\n      <td>1.011330</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Спешу расстроить: экспоненциального роста каче...</td>\n      <td>3.975339</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Мы выяснили, что лучше выбирать значение ранга...</td>\n      <td>2.645053</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Ранг 8 — золотая середина, но с моделью, у кот...</td>\n      <td>3.283998</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>При ранге 32 модель начинает работать лучше и ...</td>\n      <td>2.988543</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>С дальнейшим увеличением ранга можно увидеть р...</td>\n      <td>3.169895</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Обучение LoRA требует от 1000 до 50 000 пример...</td>\n      <td>2.055877</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>На большем количестве обучающих примеров на на...</td>\n      <td>4.647187</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>В случае fine-tune можно обучать модель целико...</td>\n      <td>2.682445</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Для больших моделей такой вариант достаточно т...</td>\n      <td>2.824097</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Обычно это называют «разморозкой»: модель по у...</td>\n      <td>2.189540</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Если «разморозить» только необходимые слои, об...</td>\n      <td>2.796245</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Full fine-tune позволяет получить максимальное...</td>\n      <td>3.249875</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Теперь мы знаем все плюсы и минусы всех подход...</td>\n      <td>3.602189</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>В то же время при fine-tune потенциал качества...</td>\n      <td>3.243859</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Кстати, это одновременно и плюс, и минус: при ...</td>\n      <td>3.599707</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>В случае с LoRA с рангом 8 или 32 есть шанс, ч...</td>\n      <td>2.633625</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Однако, если есть идеальный датасет, то full f...</td>\n      <td>2.963593</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Для нас LoRa оказался эффективным препродакшн-...</td>\n      <td>2.051240</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Это метод позволяет быстро и дёшево исследоват...</td>\n      <td>4.493104</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Однако мы понимаем, что LoRa — неидеальное реш...</td>\n      <td>4.051621</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Поэтому после того, как мы упираемся в потолок...</td>\n      <td>3.467401</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>В целом сочетание LoRa и fine-tune позволяет н...</td>\n      <td>2.801313</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Такой подход мы применили для суммаризации стр...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['sentence', 'super_score']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:39:27.388672400Z",
     "start_time": "2024-03-26T08:39:27.363194400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Он работает эффективнее, чем человек, которого посадили подбирать удачный промпт\n",
      "В целом это хороший подход, но в нашем случае он почти никогда не давал требуемых результатов с необходимым качеством\n",
      "Сам подход не может именно научить модель: задача должна быть достаточно простой для модели или в каком-то виде присутствовать в обучении\n",
      "\n",
      "New chapter: \n",
      "\n",
      "Для сложных задач интереснее LoRA и fine-tune\n",
      "На практике разница между ними в максимальном качестве, которого можно достичь: у разморозки слоёв в fine-tune предел качества выше\n",
      "Но давайте рассмотрим каждый подход подробнее\n",
      "\n",
      "New chapter: \n",
      "\n",
      "У LoRA есть параметр — ранг\n",
      "Чем больше ранг, тем более сложному навыку можно обучить модель\n",
      "\n",
      "New chapter: \n",
      "\n",
      "Но и тут есть свои нюансы\n",
      "Мы проводили эксперимент с рангом LoRA и ростом качества в зависимости от него\n",
      "\n",
      "New chapter: \n",
      "\n",
      "Шаг ранга — степень двойки (4, 8, 16, 32, 64, 128, 256, 512)\n",
      "Спешу расстроить: экспоненциального роста качества модели, увы, не происходит\n",
      "Мы выяснили, что лучше выбирать значение ранга 8 или 32\n",
      "Ранг 8 — золотая середина, но с моделью, у которой изначально было низкое качество или неудачная архитектура, вы, скорее всего, быстро упрётесь в потолок\n",
      "При ранге 32 модель начинает работать лучше и улавливать более мелкие детали\n",
      "С дальнейшим увеличением ранга можно увидеть рост метрик, но по субъективным оценкам качество падает: модель начинает цепляться за ошибки в обучающих данных и чаще галлюцинировать\n",
      "\n",
      "New chapter: \n",
      "\n",
      "Обучение LoRA требует от 1000 до 50 000 примеров для обучения\n",
      "На большем количестве обучающих примеров на наших данных мы не получали роста качества, хотя до этого была очевидная зависимость качества от количества данных\n",
      "В случае fine-tune можно обучать модель целиком — full fine-tune\n",
      "Для больших моделей такой вариант достаточно требователен к ресурсам, поэтому в качестве альтернативы можно обучать только часть слоёв\n",
      "\n",
      "New chapter: \n",
      "\n",
      "Обычно это называют «разморозкой»: модель по умолчанию «заморожена» и большинство весов зафиксированы\n",
      "Если «разморозить» только необходимые слои, обучение будет быстрее, но проблемнее — спрогнозировать, какие слои размораживать, достаточно сложно\n",
      "Full fine-tune позволяет получить максимальное качество на текущей архитектуре модели, но этот метод более требователен к количеству и качеству данных, чем LoRA и p-tune\n",
      "Теперь мы знаем все плюсы и минусы всех подходов — что же выбрать? При малом количестве данных использование fine-tune приведёт к тому, что модель будет более подвержена prompt injection — исходя из наших наблюдений, с LoRA такое случается реже\n",
      "В то же время при fine-tune потенциал качества выше — модель начинает улавливать больше интересных деталей\n",
      "Кстати, это одновременно и плюс, и минус: при недостаточно качественном датасете модель обязательно научится чему-то плохому даже из всего лишь из пары примеров\n",
      "В случае с LoRA с рангом 8 или 32 есть шанс, что такого не произойдёт\n",
      "Однако, если есть идеальный датасет, то full fine-tune даст наибольшее качество\n",
      "\n",
      "New chapter: \n",
      "\n",
      "Для нас LoRa оказался эффективным препродакшн-инструментом для проведения множества экспериментов при подготовке датасета и проверке гипотез\n",
      "Это метод позволяет быстро и дёшево исследовать различные подходы и идеи, не тратя много времени и ресурсов\n",
      "Однако мы понимаем, что LoRa — неидеальное решение\n",
      "Поэтому после того, как мы упираемся в потолок качества, переход на fine-tune даёт нам рост в качестве за счёт того, что у нас есть хорошо подготовленный качественный датасет\n",
      "В целом сочетание LoRa и fine-tune позволяет нам эффективно использовать преимущества обоих методов для достижения лучших результатов\n",
      "Такой подход мы применили для суммаризации страниц, и аналогичный подход применялся для пересказа видео.\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(df.iterrows()):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    if df['super_score'][i] < 2.3:\n",
    "        print(\"\\nNew chapter: \\n\")\n",
    "    print(df['sentence'][i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:43:06.012760600Z",
     "start_time": "2024-03-26T08:43:05.980462900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'mean_25'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_5544\\2411838073.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'super_score'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean_25\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\nlp-experements-i8WhhMzd-py3.10\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   6292\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6293\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6294\u001B[0m         ):\n\u001B[0;32m   6295\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6296\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: 'Series' object has no attribute 'mean_25'"
     ]
    }
   ],
   "source": [
    "df['super_score']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T08:41:31.993135100Z",
     "start_time": "2024-03-26T08:41:31.866098400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
